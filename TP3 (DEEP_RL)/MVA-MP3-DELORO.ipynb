{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "[Note : I assumed there was a small typo in the indices here, but without consequences\n",
    "\n",
    "\\begin{equation*}p^{\\pi}(s_{0},a_{0}, s_{1},a_{1},...,s_{T-1},a_{T-1},s_{T})=p(s_{0})\\prod_{t=0}^{T-1}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}]\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else:\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At train time (train = True) : With a probability epsilon, the agent chooses an action uniformly at random (exploration). Otherwise (with a probability 1-epsilon) it chooses the action maximizing the expected cumulative reward from his current state, ie. the Q-value of the pair state-action (exploitation). \n",
    "\n",
    "> Thus epsilon is essential as it **tradeoffs between exploration of the environment and exploitation of the learnt policy**. A current habit is thus to decrease epsilon throughout the learning (favor exploitation over exploration as the agent learns).\n",
    "\n",
    "> At test time  (train = False) : The agent follows the learnt policy, ie. chooses the action maximizing the expected cumulative reward from his current state, ie. the Q-value of the pair state-action (only exploitation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1 #self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x -1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x +1\n",
    "            else:\n",
    "                self.x = self.x - 1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "        \n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        \n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.board[self.position < 0] = 0\n",
    "        \n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature= 0.3 \n",
    "epochs_train=100 # set small when debugging\n",
    "epochs_test=50  # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The array position gives to the rat the information of where it can go (0 if the cell is accessible and -1 if not). We also store in the array the position of the rat (value of 1).\n",
    "\n",
    "> The array board gives to the rat the current positions of the cheese and poisonous cells in the environment (value of 0.5 if there is a cheese in the cell, of -1 if it is a poison, 0 if there is nothing). \n",
    "\n",
    "> Cheeses and poisons are initially generated at each episode as follows : (i) each cell has a probability temperature to contain a cheese, (ii) once cheese are generated, each cell which does not contain a cheese has a probability temperature to contain a poison.\n",
    "\n",
    "> Note : I modified several things in the code : first, i added the border at the right of the board (missing) ; secondly, i removed any cheese/poison in the border zones ; finally, i decided to remove the bouncing effects of the rat on the borders (now the rat stays in the same position if it can't go in the action direction because of a border.  Indeed, otherwise, it would have receive a wrong feedback given the potential reward in the cell of arrival)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.random.randint(0, self.n_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix='',return_trajectories=False):\n",
    "    \n",
    "    if return_trajectories:\n",
    "        trajectories = []\n",
    "        \n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "                \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "                        \n",
    "            # The agent performs an action\n",
    "            action = agent.act(state, train=False)\n",
    "            \n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "            \n",
    "            if return_trajectories:\n",
    "                trajectories.append((prev_state,action))\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score_episode = 0.5*win-lose\n",
    "        score += score_episode\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))\n",
    "    \n",
    "    if return_trajectories:\n",
    "        return trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : As score measure, I used 0.5*win - lose instead of win-lose since poison give a reward of -1 while cheese 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 6.5/14.0. Average score (-10.75)\n",
      "Win/lose count 9.0/14.0. Average score (-10.125)\n",
      "Win/lose count 9.5/21.0. Average score (-12.166666666666666)\n",
      "Win/lose count 10.5/22.0. Average score (-13.3125)\n",
      "Win/lose count 7.5/10.0. Average score (-11.9)\n",
      "Win/lose count 9.5/11.0. Average score (-10.958333333333334)\n",
      "Win/lose count 11.0/14.0. Average score (-10.607142857142858)\n",
      "Win/lose count 8.5/15.0. Average score (-10.625)\n",
      "Win/lose count 17.5/12.0. Average score (-9.805555555555555)\n",
      "Win/lose count 9.5/10.0. Average score (-9.35)\n",
      "Win/lose count 8.0/15.0. Average score (-9.5)\n",
      "Win/lose count 11.0/12.0. Average score (-9.25)\n",
      "Win/lose count 8.0/9.0. Average score (-8.923076923076923)\n",
      "Win/lose count 12.0/15.0. Average score (-8.928571428571429)\n",
      "Win/lose count 7.0/13.0. Average score (-8.966666666666667)\n",
      "Win/lose count 11.5/14.0. Average score (-8.921875)\n",
      "Win/lose count 9.5/14.0. Average score (-8.941176470588236)\n",
      "Win/lose count 10.0/15.0. Average score (-9.0)\n",
      "Win/lose count 8.5/10.0. Average score (-8.828947368421053)\n",
      "Win/lose count 6.0/15.0. Average score (-8.9875)\n",
      "Win/lose count 6.0/16.0. Average score (-9.178571428571429)\n",
      "Win/lose count 7.5/15.0. Average score (-9.272727272727273)\n",
      "Win/lose count 8.5/15.0. Average score (-9.33695652173913)\n",
      "Win/lose count 8.0/5.0. Average score (-8.989583333333334)\n",
      "Win/lose count 13.0/17.0. Average score (-9.05)\n",
      "Win/lose count 4.5/11.0. Average score (-9.038461538461538)\n",
      "Win/lose count 8.0/16.0. Average score (-9.148148148148149)\n",
      "Win/lose count 9.5/3.0. Average score (-8.758928571428571)\n",
      "Win/lose count 9.5/13.0. Average score (-8.741379310344827)\n",
      "Win/lose count 10.0/23.0. Average score (-9.05)\n",
      "Win/lose count 11.5/12.0. Average score (-8.959677419354838)\n",
      "Win/lose count 4.5/14.0. Average score (-9.046875)\n",
      "Win/lose count 9.0/15.0. Average score (-9.090909090909092)\n",
      "Win/lose count 9.5/12.0. Average score (-9.036764705882353)\n",
      "Win/lose count 10.5/16.0. Average score (-9.085714285714285)\n",
      "Win/lose count 7.0/12.0. Average score (-9.069444444444445)\n",
      "Win/lose count 8.5/11.0. Average score (-9.006756756756756)\n",
      "Win/lose count 5.5/15.0. Average score (-9.092105263157896)\n",
      "Win/lose count 6.0/8.0. Average score (-8.987179487179487)\n",
      "Win/lose count 10.5/16.0. Average score (-9.03125)\n",
      "Win/lose count 12.0/12.0. Average score (-8.957317073170731)\n",
      "Win/lose count 9.0/13.0. Average score (-8.946428571428571)\n",
      "Win/lose count 6.5/16.0. Average score (-9.034883720930232)\n",
      "Win/lose count 12.0/18.0. Average score (-9.102272727272727)\n",
      "Win/lose count 8.5/17.0. Average score (-9.183333333333334)\n",
      "Win/lose count 8.5/15.0. Average score (-9.217391304347826)\n",
      "Win/lose count 10.0/16.0. Average score (-9.25531914893617)\n",
      "Win/lose count 10.5/17.0. Average score (-9.307291666666666)\n",
      "Win/lose count 12.5/12.0. Average score (-9.23469387755102)\n",
      "Win/lose count 10.0/17.0. Average score (-9.29)\n",
      "Final score: -9.29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> I assumed there were small typos in the assertions to prove. Let us rewrite the question first : \n",
    "\n",
    "> 1. Let $\\pi$ be a policy, show that: \\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{s'\\sim p(.|s,a), ~a' \\sim \\pi(.|s')}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "> 2. Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds:  \\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim p(.|s,a)}[r(s,a)+\\gamma \\max_{a'} Q^{*}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "> 3. Finally, deduce that a plausible objective is:\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim p(.|s,a)}\\Vert r(s,a) +\\gamma \\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "> **Question 1**\n",
    "\n",
    "> $Q^{\\pi}(s,a)$ is defined as the expected cumulative reward over trajectories beginning in state $s$ with action $a$ and following policy $\\pi$. We can rewrite it as :\n",
    "\n",
    "\n",
    "> \\begin{align} Q^\\pi(s,a) &=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\n",
    "\\\\ &= r(s, a) + \\gamma E_{p^{\\pi}}[\\sum_{1 \\leq t \\leq T} \\gamma^{t - 1} r(s_t,a_t)|s_0=s,a_0=a] \n",
    "\\\\ &= r(s, a) + \\gamma \\sum_{s'} \\mathbb{P}(s_1 = s' | s_0 = s,a_0=a) \\sum_{a'} \\pi(a'|s') E_{p^{\\pi}}[\\sum_{1 \\leq t \\leq T} \\gamma^{t - 1} r(s_t,a_t)|s_1=s',a_1=a']\n",
    "\\\\ &= r(s, a) + \\gamma \\sum_{s'} \\mathbb{P}(s_1 = s' | s_0 = s,a_0=a) \\sum_{a'} \\pi(a'|s') E_{p^{\\pi}}[\\sum_{0 \\leq t \\leq T-1} \\gamma^{t} r(s_t,a_t)|s_0=s',a_0=a'] \\\\\n",
    " & = r(s,a) + \\gamma \\sum_{s'} p(s'|s,a) \\sum_{a'} \\pi(a'|s')  Q^{\\pi}(s',a')\\end{align}\n",
    "\n",
    "\n",
    "> This is the so-called Bellman equation (which tells that the expected discounted cumulative reward in state s taking action a is the sum of the immediate reward $r(s,a)$ and of the expectation of the discounted cumulative reward over all new reachable state $s' \\sim p(.|s,a)$ and taking action from state $s'$ following the policy $\\pi$ (ie. choosing $a' \\sim \\pi(.|s')$)).\n",
    "\n",
    "> Then, $$\\begin{align}\n",
    "Q^{\\pi}(s,a)& = r(s,a) + \\gamma \\sum_{s'} p(s'|s,a) \\sum_{a'} \\pi(a'|s')  Q^{\\pi}(s',a') \\\\\n",
    "&= \\sum_{s'} p(s'|s,a) \\left( r(s,a) + \\gamma \\sum_{a'} \\pi(a'|s')  Q^{\\pi}(s',a')\\right) \\\\\n",
    "&= \\sum_{s'} p(s'|s,a) \\sum_{a'} \\pi(a'|s')  \\left( r(s,a) + \\gamma Q^{\\pi}(s',a') \\right) \\\\\n",
    "&=E_{s'\\sim p(.|s,a), ~a' \\sim \\pi(.|s')}[r(s,a)+\\gamma Q^{\\pi}(s',a')].\n",
    "\\end{align}$$ \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "> **Question 2**\n",
    "\n",
    "\n",
    "> Denoting $Q^{*} = Q^{\\pi^*}$ the state-action value function associated to the optimal policy, \n",
    "\n",
    "$$\\begin{align}\n",
    "Q^{*}(s,a) &= E_{s'\\sim p(.|s,a), ~a' \\sim \\pi(.|s')}[r(s,a)+\\gamma Q^{*}(s',a')] \\\\\n",
    "&=E_{s'\\sim p(.|s,a)}   \\left[ r(s,a) + \\gamma  \\sum_{a'} \\pi(a'|s') Q^{*}(s',a') \\right].\n",
    "\\end{align}$$ \n",
    "\n",
    "\n",
    "> But the optimal policy $\\pi^*$ satisfies for any action $a$ : $$\\pi^*(a|s) = 1_{a = a_0} $$ where we set : $$a_0 = \\arg \\max_{a} Q^{*}(s,a)$$\n",
    "\n",
    "> Hence : $$\\begin{align}\n",
    "Q^{*}(s,a) &= E_{s'\\sim p(.|s,a)} \\left[ r(s,a)+\\gamma Q^{*} \\left( s',\\arg \\max_{a'} Q^{*}(s',a') \\right) \\right] \\\\\n",
    "&=E_{s'\\sim p(.|s,a)}[r(s,a)+\\gamma \\max_{a'} Q^{*}(s',a')] \\end{align}$$ \n",
    "\n",
    "*** \n",
    "\n",
    "> **Question 3**\n",
    "\n",
    "> Hence :  $$ E_{s'\\sim p(.|s,a)}[r(s,a)+\\gamma \\max_{a'} Q^{*}(s',a')- Q^{*}(s,a) ] = 0 $$\n",
    "\n",
    "> Therefore, such matrix $Q^{*}$ will minimize the following loss : \\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim p(.|s,a)}\\Vert r(s,a) +\\gamma \\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "[Note : I assumed that at state $s_t$, we select the action $a_t$ following an epsilon-greedy policy (ie. the one with highest $Q_t$ value with probability 1-epsilon, and uniformly at random otherwise]\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len(self.memory)>self.max_memory:\n",
    "            self.memory = self.memory[-self.max_memory:]\n",
    "\n",
    "    def random_access(self):\n",
    "        #len_memory = len(self.memory)\n",
    "        #idx = np.random.permutation(len_memory)\n",
    "        #return self.memory[idx]\n",
    "        idx = np.random.randint(len(self.memory))\n",
    "        return self.memory[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    \n",
    "    history_losses = []\n",
    "    history_scores = []    \n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for e in range(epoch):\n",
    "            \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "        \n",
    "        loss = 0\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        t = 0\n",
    "\n",
    "        while not game_over:\n",
    "            \n",
    "            # The agent performs an action\n",
    "            action = agent.act(state, train=True)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss += agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "            \n",
    "            t+=1\n",
    "            \n",
    "        loss /= t\n",
    "            \n",
    "        history_losses.append(loss)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score_episode = 0.5*win-lose\n",
    "        score += score_episode\n",
    "        history_scores.append(score_episode)\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, score_episode))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "    return history_losses, history_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size = 10.,  epsilon = 0.1, memory_size=100, batch_size = 16, n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        state_action_values = self.model.predict(s[None,:,:,:]).flatten()\n",
    "        return np.argmax(state_action_values)\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state))\n",
    "        \n",
    "        steps = [self.memory.random_access() for i in range(self.batch_size)]\n",
    "        \n",
    "        #states\n",
    "        input_states = [s[0] for s in steps]\n",
    "        input_states = np.array(input_states)\n",
    "        \n",
    "        #new_state, action, rew, game_over \n",
    "        tmp = np.array([s[1:] for s in steps])\n",
    "        new_states = tmp[:,0]\n",
    "        actions = tmp[:,1]\n",
    "        rewards = tmp[:,2]\n",
    "        game_over = tmp[:,3]\n",
    "        \n",
    "        print(input_states.shape, tmp.shape)\n",
    "        print(np.max(q_new_state,axis=1).shape)\n",
    "        \n",
    "        # targets\n",
    "        target_q = self.model.predict(input_states)\n",
    "        q_new_state = self.model.predict(new_states)\n",
    "        target_q[np.arange(self.batch_size),actions] = rew + (1-game_over) * self.discount * np.max(q_new_state,axis=1)\n",
    "        \n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter        \n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        #early_stopping_monitor = EarlyStopping(patience = 5)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        \n",
    "        #model.compile(\"sgd\", \"mse\")\n",
    "        model.compile(\"adam\", \"mse\")\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "\n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, lr=0.1, *args, **kwargs):\n",
    "        super(DQN_FC, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape = (5,5,self.n_state,)))\n",
    "        model.add(Dense(20))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(self.n_action))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        #opt = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        opt = sgd(lr=lr, decay=1e-4, momentum=0.0)\n",
    "        model.compile(loss=\"mse\", optimizer = opt)\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 84        \n",
      "=================================================================\n",
      "Total params: 1,104\n",
      "Trainable params: 1,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 000/100 | Loss 0.0157 | Win/lose count 3.0/1.0 (0.5)\n",
      "Epoch 001/100 | Loss 0.0125 | Win/lose count 0.5/1.0 (-0.75)\n",
      "Epoch 002/100 | Loss 0.0077 | Win/lose count 0.5/1.0 (-0.75)\n",
      "Epoch 003/100 | Loss 0.0122 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 004/100 | Loss 0.0059 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 005/100 | Loss 0.0043 | Win/lose count 0.5/3.0 (-2.75)\n",
      "Epoch 006/100 | Loss 0.0041 | Win/lose count 1.5/2.0 (-1.25)\n",
      "Epoch 007/100 | Loss 0.0048 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 008/100 | Loss 0.0063 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 009/100 | Loss 0.0066 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 010/100 | Loss 0.0054 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 011/100 | Loss 0.0046 | Win/lose count 0.5/2.0 (-1.75)\n",
      "Epoch 012/100 | Loss 0.0046 | Win/lose count 3.0/1.0 (0.5)\n",
      "Epoch 013/100 | Loss 0.0068 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 014/100 | Loss 0.0064 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 015/100 | Loss 0.0062 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 016/100 | Loss 0.0065 | Win/lose count 1.5/0 (0.75)\n",
      "Epoch 017/100 | Loss 0.0070 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 018/100 | Loss 0.0064 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 019/100 | Loss 0.0051 | Win/lose count 0/0 (0.0)\n",
      "Epoch 020/100 | Loss 0.0043 | Win/lose count 0.5/2.0 (-1.75)\n",
      "Epoch 021/100 | Loss 0.0045 | Win/lose count 0/2.0 (-2.0)\n",
      "Epoch 022/100 | Loss 0.0045 | Win/lose count 1.0/4.0 (-3.5)\n",
      "Epoch 023/100 | Loss 0.0061 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 024/100 | Loss 0.0051 | Win/lose count 0/3.0 (-3.0)\n",
      "Epoch 025/100 | Loss 0.0053 | Win/lose count 2.0/1.0 (0.0)\n",
      "Epoch 026/100 | Loss 0.0045 | Win/lose count 3.5/1.0 (0.75)\n",
      "Epoch 027/100 | Loss 0.0055 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 028/100 | Loss 0.0063 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 029/100 | Loss 0.0055 | Win/lose count 3.5/3.0 (-1.25)\n",
      "Epoch 030/100 | Loss 0.0053 | Win/lose count 0/0 (0.0)\n",
      "Epoch 031/100 | Loss 0.0052 | Win/lose count 1.0/3.0 (-2.5)\n",
      "Epoch 032/100 | Loss 0.0044 | Win/lose count 1.5/4.0 (-3.25)\n",
      "Epoch 033/100 | Loss 0.0043 | Win/lose count 4.0/1.0 (1.0)\n",
      "Epoch 034/100 | Loss 0.0044 | Win/lose count 1.5/3.0 (-2.25)\n",
      "Epoch 035/100 | Loss 0.0050 | Win/lose count 3.5/1.0 (0.75)\n",
      "Epoch 036/100 | Loss 0.0052 | Win/lose count 0/0 (0.0)\n",
      "Epoch 037/100 | Loss 0.0056 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 038/100 | Loss 0.0065 | Win/lose count 1.0/2.0 (-1.5)\n",
      "Epoch 039/100 | Loss 0.0059 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 040/100 | Loss 0.0062 | Win/lose count 1.5/0 (0.75)\n",
      "Epoch 041/100 | Loss 0.0064 | Win/lose count 4.0/4.0 (-2.0)\n",
      "Epoch 042/100 | Loss 0.0052 | Win/lose count 0/1.0 (-1.0)\n",
      "Epoch 043/100 | Loss 0.0047 | Win/lose count 3.0/0 (1.5)\n",
      "Epoch 044/100 | Loss 0.0057 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 045/100 | Loss 0.0053 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 046/100 | Loss 0.0055 | Win/lose count 2.0/3.0 (-2.0)\n",
      "Epoch 047/100 | Loss 0.0054 | Win/lose count 1.0/4.0 (-3.5)\n",
      "Epoch 048/100 | Loss 0.0068 | Win/lose count 2.0/7.0 (-6.0)\n",
      "Epoch 049/100 | Loss 0.0079 | Win/lose count 2.5/2.0 (-0.75)\n",
      "Epoch 050/100 | Loss 0.0096 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 051/100 | Loss 0.0082 | Win/lose count 1.5/0 (0.75)\n",
      "Epoch 052/100 | Loss 0.0096 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 053/100 | Loss 0.0088 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 054/100 | Loss 0.0086 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 055/100 | Loss 0.0080 | Win/lose count 2.0/2.0 (-1.0)\n",
      "Epoch 056/100 | Loss 0.0079 | Win/lose count 2.5/1.0 (0.25)\n",
      "Epoch 057/100 | Loss 0.0083 | Win/lose count 1.0/3.0 (-2.5)\n",
      "Epoch 058/100 | Loss 0.0074 | Win/lose count 0/0 (0.0)\n",
      "Epoch 059/100 | Loss 0.0066 | Win/lose count 2.0/0 (1.0)\n",
      "Epoch 060/100 | Loss 0.0075 | Win/lose count 4.0/1.0 (1.0)\n",
      "Epoch 061/100 | Loss 0.0068 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 062/100 | Loss 0.0075 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 063/100 | Loss 0.0059 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 064/100 | Loss 0.0072 | Win/lose count 0.5/1.0 (-0.75)\n",
      "Epoch 065/100 | Loss 0.0074 | Win/lose count 2.0/2.0 (-1.0)\n",
      "Epoch 066/100 | Loss 0.0065 | Win/lose count 0/0 (0.0)\n",
      "Epoch 067/100 | Loss 0.0047 | Win/lose count 1.0/2.0 (-1.5)\n",
      "Epoch 068/100 | Loss 0.0049 | Win/lose count 1.0/2.0 (-1.5)\n",
      "Epoch 069/100 | Loss 0.0043 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 070/100 | Loss 0.0060 | Win/lose count 3.0/4.0 (-2.5)\n",
      "Epoch 071/100 | Loss 0.0048 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 072/100 | Loss 0.0046 | Win/lose count 1.5/3.0 (-2.25)\n",
      "Epoch 073/100 | Loss 0.0048 | Win/lose count 3.0/2.0 (-0.5)\n",
      "Epoch 074/100 | Loss 0.0052 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 075/100 | Loss 0.0051 | Win/lose count 4.0/2.0 (0.0)\n",
      "Epoch 076/100 | Loss 0.0050 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 077/100 | Loss 0.0051 | Win/lose count 1.5/2.0 (-1.25)\n",
      "Epoch 078/100 | Loss 0.0052 | Win/lose count 4.5/0 (2.25)\n",
      "Epoch 079/100 | Loss 0.0063 | Win/lose count 7.5/6.0 (-2.25)\n",
      "Epoch 080/100 | Loss 0.0067 | Win/lose count 2.0/5.0 (-4.0)\n",
      "Epoch 081/100 | Loss 0.0074 | Win/lose count 2.5/4.0 (-2.75)\n",
      "Epoch 082/100 | Loss 0.0070 | Win/lose count 2.0/2.0 (-1.0)\n",
      "Epoch 083/100 | Loss 0.0073 | Win/lose count 1.0/2.0 (-1.5)\n",
      "Epoch 084/100 | Loss 0.0073 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 085/100 | Loss 0.0082 | Win/lose count 2.0/2.0 (-1.0)\n",
      "Epoch 086/100 | Loss 0.0082 | Win/lose count 1.5/2.0 (-1.25)\n",
      "Epoch 087/100 | Loss 0.0081 | Win/lose count 0/2.0 (-2.0)\n",
      "Epoch 088/100 | Loss 0.0073 | Win/lose count 3.0/0 (1.5)\n",
      "Epoch 089/100 | Loss 0.0055 | Win/lose count 1.5/2.0 (-1.25)\n",
      "Epoch 090/100 | Loss 0.0060 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 091/100 | Loss 0.0053 | Win/lose count 0.5/1.0 (-0.75)\n",
      "Epoch 092/100 | Loss 0.0041 | Win/lose count 0.5/0 (0.25)\n",
      "Epoch 093/100 | Loss 0.0043 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 094/100 | Loss 0.0033 | Win/lose count 0.5/1.0 (-0.75)\n",
      "Epoch 095/100 | Loss 0.0037 | Win/lose count 0/0 (0.0)\n",
      "Epoch 096/100 | Loss 0.0049 | Win/lose count 0/0 (0.0)\n",
      "Epoch 097/100 | Loss 0.0053 | Win/lose count 1.0/3.0 (-2.5)\n",
      "Epoch 098/100 | Loss 0.0046 | Win/lose count 2.5/1.0 (0.25)\n",
      "Epoch 099/100 | Loss 0.0041 | Win/lose count 1.0/1.0 (-0.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "env = Environment(grid_size=size, max_time=T, temperature=temperature)\n",
    "agent_dqn_fc = DQN_FC(grid_size=size, lr=.01, epsilon = 0.01, memory_size=2000, batch_size = 32)\n",
    "history_losses_dqn_fc, history_scores_dqn_fc = train(agent_dqn_fc, env, epochs_train, prefix='fc_train')\n",
    "\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_losses_dqn_fc,marker=\"+\",color=\"b\",label=\"\")\n",
    "plt.xlabel(\"episodes\") ; plt.ylabel(\"mean training loss during episod\") ; plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_scores_dqn_fc,marker=\"+\",color=\"r\",label=\"\")\n",
    "plt.xlabel(\"episodes\") ; plt.ylabel(\"score during episod (0.5*win-lose)\") ; plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, lr=0.1, *args, **kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "                \n",
    "        model = Sequential()\n",
    "    \n",
    "        model.add(Conv2D(8, (3, 3), activation='relu', input_shape=(5,5,self.n_state,)))\n",
    "        model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.n_action))\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        #opt = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        opt = sgd(lr=lr, decay=1e-4, momentum=0.0)\n",
    "        model.compile(loss=\"mse\", optimizer = opt)\n",
    "        \n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 8)           152       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 16)          1168      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 1,388\n",
      "Trainable params: 1,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 000/100 | Loss 0.0336 | Win/lose count 3.5/6.0 (-4.25)\n",
      "Epoch 001/100 | Loss 0.0122 | Win/lose count 2.5/5.0 (-3.75)\n",
      "Epoch 002/100 | Loss 0.0099 | Win/lose count 3.5/4.0 (-2.25)\n",
      "Epoch 003/100 | Loss 0.0087 | Win/lose count 1.5/3.0 (-2.25)\n",
      "Epoch 004/100 | Loss 0.0076 | Win/lose count 2.5/2.0 (-0.75)\n",
      "Epoch 005/100 | Loss 0.0074 | Win/lose count 3.5/4.0 (-2.25)\n",
      "Epoch 006/100 | Loss 0.0068 | Win/lose count 1.5/6.0 (-5.25)\n",
      "Epoch 007/100 | Loss 0.0074 | Win/lose count 3.0/4.0 (-2.5)\n",
      "Epoch 008/100 | Loss 0.0067 | Win/lose count 4.0/1.0 (1.0)\n",
      "Epoch 009/100 | Loss 0.0070 | Win/lose count 1.0/1.0 (-0.5)\n",
      "Epoch 010/100 | Loss 0.0054 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 011/100 | Loss 0.0049 | Win/lose count 1.5/2.0 (-1.25)\n",
      "Epoch 012/100 | Loss 0.0046 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 013/100 | Loss 0.0059 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 014/100 | Loss 0.0053 | Win/lose count 1.5/2.0 (-1.25)\n",
      "Epoch 015/100 | Loss 0.0050 | Win/lose count 1.5/4.0 (-3.25)\n",
      "Epoch 016/100 | Loss 0.0049 | Win/lose count 3.0/1.0 (0.5)\n",
      "Epoch 017/100 | Loss 0.0042 | Win/lose count 0/2.0 (-2.0)\n",
      "Epoch 018/100 | Loss 0.0038 | Win/lose count 2.0/4.0 (-3.0)\n",
      "Epoch 019/100 | Loss 0.0042 | Win/lose count 2.0/1.0 (0.0)\n",
      "Epoch 020/100 | Loss 0.0048 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 021/100 | Loss 0.0051 | Win/lose count 0.5/4.0 (-3.75)\n",
      "Epoch 022/100 | Loss 0.0050 | Win/lose count 4.5/2.0 (0.25)\n",
      "Epoch 023/100 | Loss 0.0052 | Win/lose count 3.0/4.0 (-2.5)\n",
      "Epoch 024/100 | Loss 0.0057 | Win/lose count 3.5/3.0 (-1.25)\n",
      "Epoch 025/100 | Loss 0.0051 | Win/lose count 4.5/2.0 (0.25)\n",
      "Epoch 026/100 | Loss 0.0050 | Win/lose count 4.0/2.0 (0.0)\n",
      "Epoch 027/100 | Loss 0.0066 | Win/lose count 4.0/8.0 (-6.0)\n",
      "Epoch 028/100 | Loss 0.0052 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 029/100 | Loss 0.0063 | Win/lose count 4.5/5.0 (-2.75)\n",
      "Epoch 030/100 | Loss 0.0059 | Win/lose count 2.0/1.0 (0.0)\n",
      "Epoch 031/100 | Loss 0.0060 | Win/lose count 2.0/1.0 (0.0)\n",
      "Epoch 032/100 | Loss 0.0060 | Win/lose count 3.0/4.0 (-2.5)\n",
      "Epoch 033/100 | Loss 0.0068 | Win/lose count 2.5/11.0 (-9.75)\n",
      "Epoch 034/100 | Loss 0.0069 | Win/lose count 4.5/1.0 (1.25)\n",
      "Epoch 035/100 | Loss 0.0068 | Win/lose count 6.0/8.0 (-5.0)\n",
      "Epoch 036/100 | Loss 0.0072 | Win/lose count 2.5/1.0 (0.25)\n",
      "Epoch 037/100 | Loss 0.0070 | Win/lose count 1.0/2.0 (-1.5)\n",
      "Epoch 038/100 | Loss 0.0064 | Win/lose count 2.5/4.0 (-2.75)\n",
      "Epoch 039/100 | Loss 0.0061 | Win/lose count 2.5/4.0 (-2.75)\n",
      "Epoch 040/100 | Loss 0.0062 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 041/100 | Loss 0.0057 | Win/lose count 2.0/3.0 (-2.0)\n",
      "Epoch 042/100 | Loss 0.0061 | Win/lose count 2.5/1.0 (0.25)\n",
      "Epoch 043/100 | Loss 0.0049 | Win/lose count 1.5/4.0 (-3.25)\n",
      "Epoch 044/100 | Loss 0.0054 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 045/100 | Loss 0.0045 | Win/lose count 1.0/2.0 (-1.5)\n",
      "Epoch 046/100 | Loss 0.0050 | Win/lose count 4.0/2.0 (0.0)\n",
      "Epoch 047/100 | Loss 0.0045 | Win/lose count 3.5/1.0 (0.75)\n",
      "Epoch 048/100 | Loss 0.0047 | Win/lose count 2.5/5.0 (-3.75)\n",
      "Epoch 049/100 | Loss 0.0049 | Win/lose count 7.0/1.0 (2.5)\n",
      "Epoch 050/100 | Loss 0.0049 | Win/lose count 0/1.0 (-1.0)\n",
      "Epoch 051/100 | Loss 0.0042 | Win/lose count 0.5/1.0 (-0.75)\n",
      "Epoch 052/100 | Loss 0.0050 | Win/lose count 2.5/5.0 (-3.75)\n",
      "Epoch 053/100 | Loss 0.0043 | Win/lose count 6.0/3.0 (0.0)\n",
      "Epoch 054/100 | Loss 0.0042 | Win/lose count 1.0/3.0 (-2.5)\n",
      "Epoch 055/100 | Loss 0.0044 | Win/lose count 2.0/0 (1.0)\n",
      "Epoch 056/100 | Loss 0.0049 | Win/lose count 4.0/4.0 (-2.0)\n",
      "Epoch 057/100 | Loss 0.0047 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 058/100 | Loss 0.0042 | Win/lose count 4.5/2.0 (0.25)\n",
      "Epoch 059/100 | Loss 0.0042 | Win/lose count 4.0/2.0 (0.0)\n",
      "Epoch 060/100 | Loss 0.0040 | Win/lose count 2.0/2.0 (-1.0)\n",
      "Epoch 061/100 | Loss 0.0047 | Win/lose count 2.0/3.0 (-2.0)\n",
      "Epoch 062/100 | Loss 0.0046 | Win/lose count 2.0/2.0 (-1.0)\n",
      "Epoch 063/100 | Loss 0.0037 | Win/lose count 3.5/1.0 (0.75)\n",
      "Epoch 064/100 | Loss 0.0041 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 065/100 | Loss 0.0040 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 066/100 | Loss 0.0039 | Win/lose count 7.0/2.0 (1.5)\n",
      "Epoch 067/100 | Loss 0.0040 | Win/lose count 2.0/0 (1.0)\n",
      "Epoch 068/100 | Loss 0.0035 | Win/lose count 3.5/1.0 (0.75)\n",
      "Epoch 069/100 | Loss 0.0038 | Win/lose count 4.0/4.0 (-2.0)\n",
      "Epoch 070/100 | Loss 0.0049 | Win/lose count 4.0/5.0 (-3.0)\n",
      "Epoch 071/100 | Loss 0.0042 | Win/lose count 3.5/0 (1.75)\n",
      "Epoch 072/100 | Loss 0.0045 | Win/lose count 2.5/2.0 (-0.75)\n",
      "Epoch 073/100 | Loss 0.0049 | Win/lose count 2.0/4.0 (-3.0)\n",
      "Epoch 074/100 | Loss 0.0047 | Win/lose count 1.0/0 (0.5)\n",
      "Epoch 075/100 | Loss 0.0056 | Win/lose count 3.0/5.0 (-3.5)\n",
      "Epoch 076/100 | Loss 0.0050 | Win/lose count 2.5/2.0 (-0.75)\n",
      "Epoch 077/100 | Loss 0.0047 | Win/lose count 2.0/1.0 (0.0)\n",
      "Epoch 078/100 | Loss 0.0055 | Win/lose count 1.5/5.0 (-4.25)\n",
      "Epoch 079/100 | Loss 0.0059 | Win/lose count 2.5/7.0 (-5.75)\n",
      "Epoch 080/100 | Loss 0.0050 | Win/lose count 3.0/4.0 (-2.5)\n",
      "Epoch 081/100 | Loss 0.0048 | Win/lose count 3.0/3.0 (-1.5)\n",
      "Epoch 082/100 | Loss 0.0055 | Win/lose count 7.0/2.0 (1.5)\n",
      "Epoch 083/100 | Loss 0.0058 | Win/lose count 1.5/4.0 (-3.25)\n",
      "Epoch 084/100 | Loss 0.0053 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 085/100 | Loss 0.0059 | Win/lose count 4.5/4.0 (-1.75)\n",
      "Epoch 086/100 | Loss 0.0059 | Win/lose count 2.0/3.0 (-2.0)\n",
      "Epoch 087/100 | Loss 0.0053 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 088/100 | Loss 0.0064 | Win/lose count 2.5/5.0 (-3.75)\n",
      "Epoch 089/100 | Loss 0.0061 | Win/lose count 4.5/1.0 (1.25)\n",
      "Epoch 090/100 | Loss 0.0061 | Win/lose count 5.5/2.0 (0.75)\n",
      "Epoch 091/100 | Loss 0.0059 | Win/lose count 5.0/4.0 (-1.5)\n",
      "Epoch 092/100 | Loss 0.0061 | Win/lose count 1.5/1.0 (-0.25)\n",
      "Epoch 093/100 | Loss 0.0051 | Win/lose count 3.0/0 (1.5)\n",
      "Epoch 094/100 | Loss 0.0048 | Win/lose count 3.5/2.0 (-0.25)\n",
      "Epoch 095/100 | Loss 0.0051 | Win/lose count 2.5/3.0 (-1.75)\n",
      "Epoch 096/100 | Loss 0.0050 | Win/lose count 2.0/1.0 (0.0)\n",
      "Epoch 097/100 | Loss 0.0049 | Win/lose count 5.0/2.0 (0.5)\n",
      "Epoch 098/100 | Loss 0.0042 | Win/lose count 1.5/3.0 (-2.25)\n",
      "Epoch 099/100 | Loss 0.0045 | Win/lose count 2.5/3.0 (-1.75)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history_losses_dqn_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c5b0ccbeb493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_losses_dqn_fc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dqn_fc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_losses_dqn_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dqn_cnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"episodes\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean training loss during episod\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_losses_dqn_cnn' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztvXuYFNW19/9ZMAKCERRRA6iAgIIaDU6IRrzhDZMYTLz8NDeTn5eTGHPM7RiNURoTT+Kbu8fLOZ7o6+XkjRpjDOaoGKPG+IroKN7QEEdULhpBFFQMwjDr/WPVPlXT05fqnp7unqn1eZ5+qmv3rupdXdX1rbX22muLquI4juM4AxrdAMdxHKc5cEFwHMdxABcEx3EcJ8IFwXEcxwFcEBzHcZwIFwTHcRwHcEFwHMdxIlwQHMdxHMAFwXEcx4loaXQDKmG77bbTcePGNboZjuM4fYrHHnvsdVUdVa5enxKEcePG0dbW1uhmOI7j9ClE5OU09VK5jERklogsEZF2ETm3wOeDReSm6POFIjIuKh8pIveJyDsiclneNoNE5CoR+ZuI/FVEjkvTFsdxHKd3KGshiMhA4HLgCGAF8KiIzFPVZxPVTgXeVNWJInIScAnw/wEbgAuAPaNXkvOBVao6WUQGANv2+Ggcx3GcqkljIUwH2lV1qapuBG4EZufVmQ1cF72/BThMRERV16vqg5gw5PP/Az8AUNVOVX29qiNwHMdxakIaQRgDLE+sr4jKCtZR1Q5gHTCy2A5FZET09nsi8riI/EZEdkjdasdxHKfmNCrstAUYCzykqtOABcCPC1UUkTNEpE1E2lavXl3PNjqO42SKNIKwEtgpsT42KitYR0RagOHAmhL7XAO8C9warf8GmFaooqpepaqtqto6alTZqKmi5HJVb+o4jpMJ0gjCo8AkERkvIoOAk4B5eXXmAadE748H7tUSU7FFn90OHBIVHQY8W6x+LZg7tzf37jiO0/cpG2Wkqh0ichYwHxgIXKOqi0XkIqBNVecBVwM3iEg78AYmGgCIyEvA1sAgETkWODKKUPp2tM3PgdXAF2t7aDGXXVa+juM4TtaRvjSncmtrq1YyMC2XK2wZzJnjLiTHcbKDiDymqq3l6vXrXEa5HKjCjBm2rmovFwPHcZzu9GtBCAwf3ugWOI7jND+ZEYRttml0KxzHcZqbzAjCwIGNboXjOE5zkxlBWLfO+g8cx3GcwmRGEDZtgg2FMio5juM4QIYEAcxKcBzHcQqTKUFYu7ax7XAcx2lmMiUIbiE4juMUxwXBcRzHAVwQHMdxnAgXBMdxHAfIiCCMiOZnc0FwHMcpTiYEYautQMQFwXEcpxSZEIQBA2DrrV0QHMdxSpEJQYA4fYXjOI5TGBcEx3EcB3BBcBzHcSIyJQieusJxHKc4mRIEtxAcx3GK44LgOI7jABkUBJ8kx3EcpzCZEoSODvjHPxrdEsdxnOYklSCIyCwRWSIi7SJyboHPB4vITdHnC0VkXFQ+UkTuE5F3ROSyIvueJyLP9OQg0uD5jBzHcUpTVhBEZCBwOXA0MBU4WUSm5lU7FXhTVScCPwMuico3ABcA3yqy708B71TX9MpwQXAcxylNGgthOtCuqktVdSNwIzA7r85s4Lro/S3AYSIiqrpeVR/EhKELIrIV8A3g+1W3vgI8wZ3jOE5p0gjCGGB5Yn1FVFawjqp2AOuAkWX2+z3gJ8C7qVraQ9xCcBzHKU1DOpVFZB9gV1X9XYq6Z4hIm4i0rV69uurvdEFwHMcpTRpBWAnslFgfG5UVrCMiLcBwYE2Jfe4PtIrIS8CDwGQRub9QRVW9SlVbVbV11KhRKZpbGBcEx3Gc0qQRhEeBSSIyXkQGAScB8/LqzANOid4fD9yrWjziX1WvVNXRqjoOmAH8TVUPqbTxlRAEwdNXOI7jFKalXAVV7RCRs4D5wEDgGlVdLCIXAW2qOg+4GrhBRNqBNzDRACCyArYGBonIscCRqvps7Q+lND5JjuM4TmnKCgKAqt4B3JFXdmHi/QbghCLbjiuz75eAPdO0oyf4JDmO4zilycxIZfB8Ro7jOKVwQXAcx3EAFwTHcRwnwgXBcRzHAVwQHMdxnAgXBMdxHAfImCCMGOGT5DiO4xQjU4Lgk+Q4juMUJ3OCAJ6+wnEcpxCZFATvR3Acx+mOC4LjOI4DuCA4juM4ES4IjuM4DuCC4DiO40S4IDiO4zhAxgTBJ8lxHMcpTqYEIUySc/fdjW6J4zhO85EpQQBzGz3ySKNb4TiO03xkUhAcx3Gc7mRGEHI56z94+mlbF7FXLtfIVjmO4zQPmRIEVTjqKFtXtZcLguM4jpEZQQgMHVr8MxcHx3GyTCYFYcSIwp/NnVvftjiO4zQTqQRBRGaJyBIRaReRcwt8PlhEboo+Xygi46LykSJyn4i8IyKXJeoPFZH/FpG/ishiEflhrQ6oHMOGweDB3csfe6xeLXAcx2lOygqCiAwELgeOBqYCJ4vI1LxqpwJvqupE4GfAJVH5BuAC4FsFdv1jVd0d+CBwgIgcXd0hVMbQofDuu/F66GxubbV172x2HCerpLEQpgPtqrpUVTcCNwKz8+rMBq6L3t8CHCYioqrrVfVBTBj+B1V9V1Xvi95vBB4HxvbgOFITBCFMoxk6m487LrTNO5sdx8kmaQRhDLA8sb4iKitYR1U7gHXAyDQNEJERwDHAn9LU7ynDhsHmzbBxY9fy9evr8e2O4zjNS0M7lUWkBfg1cKmqLi1S5wwRaRORttWrV/f4O0OUUdJtBLEgBMvBcRwna6QRhJXATon1sVFZwTrRTX44sCbFvq8CnlfVnxeroKpXqWqrqraOGjUqxS5LU04QNm3q8Vc4juP0SdIIwqPAJBEZLyKDgJOAeXl15gGnRO+PB+5VLf2sLSLfx4Tja5U1uWeUE4QNG3Acx8kkLeUqqGqHiJwFzAcGAteo6mIRuQhoU9V5wNXADSLSDryBiQYAIvISsDUwSESOBY4E3gLOB/4KPC4iAJep6i9reXCFGDbMlvl9BklB2Hrr3m6F4zhO81FWEABU9Q7gjryyCxPvNwAnFNl2XJHdSrom1ha3EBzHcQqTyZHKUFwQ3nuvvu1xHMdpFlwQgI6OOAzVLQTHcbJK5gShUB9C8r0LguM4WSVzglDIQnBBcBzHcUHo9t4FwXGcrJI5QQguI7cQHMdxupI5QRgyxJbeh+A4jtOVzAmCSPcU2ElB8LBTx3GySuYEAUoLglsIjuNklUwKwrBhLgiO4zj5ZFIQhg71PgTHcZx8MisIbiE4juN0xQUBFwTHcRzIqCAMG9bdZdTSYuUuCI7jZJVMCkIhC2HYMBg82MNOHcfJLqnmQ+hvFBMEcAvBcZzs4oJALAibN7sgOI6TXTIpCIX6EIYNszkRXBAcx8kqmRSEYCGoWiqLIAgDBrggOI6TXTLbqdzZGc+SFgRhyBAXBMdxsksmBSE/Bfa778ZRRi4IjuNklUwKQpgkJ/QjJC0EDzt1HCerZFoQgoXgLiPHcZyUgiAis0RkiYi0i8i5BT4fLCI3RZ8vFJFxUflIEblPRN4RkcvyttlXRJ6OtrlURKQWB5SGQoIwdKgLguM42aasIIjIQOBy4GhgKnCyiEzNq3Yq8KaqTgR+BlwSlW8ALgC+VWDXVwKnA5Oi16xqDqAakn0IqnEfgguC4zhZJo2FMB1oV9WlqroRuBGYnVdnNnBd9P4W4DAREVVdr6oPYsLwP4jI+4GtVfVhVVXgeuDYnhxIJST7EP7xDxMFFwTHcbJOGkEYAyxPrK+IygrWUdUOYB0wssw+V5TZZ6+RdBmFjmUXBMdxsk7TdyqLyBki0iYibatXr67JPosJgoedOo6TZdIIwkpgp8T62KisYB0RaQGGA2vK7HNsmX0CoKpXqWqrqraOGjUqRXPLk+xDyLcQNm2yQWuO4zhZI40gPApMEpHxIjIIOAmYl1dnHnBK9P544N6ob6Agqvoq8JaI7BdFF30e+H3Fra+SZB9CviCAj0VwHCeblBWEqE/gLGA+8Bxws6ouFpGLROQTUbWrgZEi0g58A/if0FQReQn4KfAFEVmRiFA6E/gl0A68ANxZm0MqT6k+BHC3kVM9uVxl5Y7TTEiJB/mmo7W1Vdva2nq8H1UYOBC++12YPh2OOQYWLoRFi+BLX4JXXoH3v78GDXYyh4hdX0leew123LF7uePUCxF5TFVby9Vr+k7l3kAkznjqFoJTK55/vntZZyfstVf92+I41ZBJQQAThPw+hMGD7b0LglMJuZw9ZEyebOsi9jrkELNEQ3BcKHf3kdOsZHI+BHALwakduRwcdhgcdJCtJ11D//f/wowZ9j6kSHGcZiWzFsKwYcUFwaOMnEpZvrxw+dKl8ftHHqlPWxynWjIrCMFl9O67ZsZvuaVbCE71BEHYcceu5UuX2vUFZi04TjPjLqPIjBdxQXCqJwjC+vXx1KxggjBmDIwYAQ8+2Lj2OU4aMm0hBEEII5ddEJxqCYLw9tvw+utx+YsvwoQJcMAB8NBDsHlzY9rnOGnIrCAk+xBcEJyesmwZDBpk7194IS5fuhTGj7eO5bfegmeeaUz7HCcNmRWEZNhpEAQPO3WqZfly2H9/ex8EYcMGWLnSLIQQaeRuI6eZybQgJPsQwKOMnOp4911YswYOPND6DoIgvPyyLSdMgF12sb4E71h2mhkXBHcZOT1kRTSzx6RJdtMPghBCTsePN6E44AC3EJzmJrOC4H0ITq0IHco77QS77grt7bYeBGHCBFvOmGF1v/71+rfRcdKQWUEYOtTyzLzxhvchOD0jCMLOO8PEiV0thCFD4rEJoR/h5z+vfxsdJw2ZFgSAVatiQRgwwCJFXBCcSgiCMHasWQivvQbvvGMhp8FdBJbk7n3vs/c+CZPTjGRWEIIIbNgQvwefRtOpnOXLYfvt7drZdVcrW7rUXsFdlMvBFlvYOAWwpHchAZ7jNAuZFYRkkrGkIAwZ4oLgVMayZdZ/ALEgvPBCd0FQ7WoZXHMN/PnPdW2q45TEBYHuguBhp04lLF/eXRAeecSsgfHju9YN7qMjjoAzzqhfGx0nDS4IuIXg9IykIIwYAdtuC3/8o60HCyHJwQfb5x0dtu7zJDjNQmYFISkCLghOtaxbZ5ZAEAQwK+Hxx+19IUG4/35zH33/+7a+cqWt+3zMTqPJrCC4heDUgmTIaWDixHiSnHyXUZJPftKW8+aV/o65c6tvn+NUggsCLghO9SQHpQVCP8KoUbDVVsW3nTLF3Eu/+13xOvPn97yNTnncCjNcEPCwU6d6SglCyH5aDBE47TS4915Yu7brZ2Ge5lmz4rrez1Bbkr+lW2FGZgXB+xCcWrB8uQ1ofP/747IgCCtXlt/+2GOtc/mOO7qW53ImFIEHHyzdz+BUzty5sHo1XH+9ra9bZ8ss/8apBEFEZonIEhFpF5FzC3w+WERuij5fKCLjEp+dF5UvEZGjEuVfF5HFIvKMiPxaRIbU4oDS4mGnTi1YvhxGj4aWxNyDQRDS8OEPW2qL227r/tmVV8Yup4ULe9ZOpyuLF9ty++3hlFPs/YgRZoVl2VooKwgiMhC4HDgamAqcLCJT86qdCrypqhOBnwGXRNtOBU4C9gBmAVeIyEARGQP8M9CqqnsCA6N6dWPw4Dgm3C0Ep1qSg9LAni7HjInXy7l6BgyA2bPhzjvhu9+Ny1991foWzjgDtt7axjU4PSe44vbcs/tnybKszmyXxkKYDrSr6lJV3QjcCMzOqzMbuC56fwtwmIhIVH6jqr6nqi8C7dH+wOZz3lJEWoChwCs9O5TKEImtBBcEp1qSYxAgHpEcoozC+1JuiE9+0nIfXXxxXHb11eZK+tKX4KijXBBqRTg/IRw4ea6Ss9m1tGSzzyaNIIwBlifWV0RlBeuoagewDhhZbFtVXQn8GFgGvAqsU9W7qzmAnhCEwAXBqQZVmwth+fLydUtx6KFmBYD5tDdvhh/9CA4/3OZYmD7dEuWtXt3zNjvwyitxavLAnDl2Pt9809YvvDCbfTYN6VQWkW0w62E8MBoYJiKfLVL3DBFpE5G21TX+RwQLIdmf4FFGTlpef92ulQULCn8+Z075feRyds299Zatb7+9PZ2+9RZ8+ctWNj2yqd1KqA1h1rrTTovLwo1/xAhbJjv0s0QaQVgJJIxixkZlBetELqDhwJoS2x4OvKiqq1V1E3Ar8JFCX66qV6lqq6q2jho1KkVz0zN0qIUGJjsEg4UQzEjHKcZLL5X+PM3TZb6L6QtfiK/HY46x5b77Wl+DC0JtePBB++9fcUXhzw84AB5+2CbPyhppBOFRYJKIjBeRQVjnb/7YynlA1FfP8cC9qqpR+UlRFNJ4YBLwCOYq2k9EhkZ9DYcBz/X8cCpj2DD7oyUZMsQyUoY8M45TiFwufnKH2o0TuPba+NobNMj2+aMfWYenC0Jt+MtfYL/9LB15IS680M5BFqc7bSlXQVU7ROQsYD4WDXSNqi4WkYuANlWdB1wN3CAi7cAbRBFDUb2bgWeBDuArqroZWCgitwCPR+WLgKtqf3ilGTq0u3soTKP53nvFLxjHyeVstr1rrrEnyVpYlHPmxIIi0nWfK1fCrbdaWYiOcyrnrbfgySe7RnTlc8AB9t+/917r0M8SqfoQVPUOVZ2sqruq6sVR2YWRGKCqG1T1BFWdqKrTVXVpYtuLo+12U9U7E+VzVHV3Vd1TVT+nqnWP/k/2HQR8XmUnLU8+abOg1YpS1sX06SZAYXrOWu03azz8sHkADjyweJ1hw8yCyGI/QiZHKodY5DsjeUqa+y4IThpUTRD23jtd53Gl5O/zwx+2ZTG3UambfpYHWuXz4IM2W134PYsxc6ZlrA1RR1khs4JQLFbcBcFJw7Jllupg77175wk8f59Tp5pF+4tfFK5f6Kb/9tvw1a/WvGlNS5rz8Je/wD77xHNbF2PmTLMksjajXSYFoRSDB9vSBcEpxZNP2nLvvevzfS0tFm1UyEIodK3mcja24bLLbL1cp3dfdyu98055S2jjRrMQZswov78Pfxi23BJ+8IPatK+vkHlByDfN3UJw0hAEoZZ9COUIbo6Qayu4Prfc0taTN/1cDk4/Pd623Ijpvu5WOvzw4p+FY160yKKH0gjC4MFWL2uRXZkXhPw/iAuCk4Ynn7QkduVcD7Ug3Ph//GNbHzIkjjRShZNPtvcXX9z1pn///eX3295uGVf7KuG3Ccn/CllCc+fCa69ZOhBIJwhgbiOwbTODqvaZ17777qu9zQMP2LPUPff0+lc5fZiJE1U/9an6fucrr9i1+dOfdi0fN87KDzqoe11Q3W23wvuL7Yaurzlzeu0QeoUbbojb/olPdP3sj3+s/DjnzOkfv0sSbIhA2Xts5i2EfNxCcMrxzjsW/lmv/oNAmHPhoYfisr//3UZMDxli5W+/beWhM3THHQvP2va1r9ly//3h4IPtfZpEfM3I3XfDdtvZ+3nz4OmnY8vhiCO61y93nCHoZMkSW7/++r75u1SDC0IefUUQsnBxNitPP203iHoLAtiI5YceiiPkQh6lCy4w//h999n6/fdbp/JHP2oRUYFwowzRSgsWxOLRF5PnqZogHH44nHOOjSH44Q/hH/+wjKajR8f1Kh08GAT4lbrmYW4sLgh59JUoo77eCdiXeeopWzZCEL70JbtBhZv8ggWW4uKssyws9e4oZ/Cf/2y+8gkT7Eb/j39YeS4Hf/xjvD9VC8WEvjkJz9NPm4//yCPhkkssIeCNN8L/+l+WhfaWW7rWr2TMyPveZ7+tC0KG6QsWQsiM6TSGJ5+0p+9ddqn/d38kSgEZ3EYLFsC0adaeQw+F+fPtBvnXv5oraOedrV4yRfff/tZ1n9OmWVjrww/3fvtrTRC34Br6xjfi5ICXXWYusaQIVGpZT5jggpBpGiUIaTNjisDw4bbuE683httvhw98oDE5hfbay9wiCxZYXH1bm930wJ6S29stQR4UF4Tnnzdr4sILbX3oUDuevigId98NU6bA2LH2Pxg92n4XgH/6p56fo9Gj082N3V9wQcijUYKQxgWUy8HatXHc+e9/n53Ormahs9MmxWmEuwjs6Xf6dLMQnnzSrtMgCCERWy5nHcnTpsWzuSX7EZ5/HiZO7HrN7befxdz3pakjN2yABx4wIYTqZqsrx+jRbiFkmmS203rx7LPp6958c+wP/u1ve6c9TnFefNGWjRIEMLfRE0/APffYehCEyZPNjbVhQ5yxc8wYe0rOF4RJk7ruc7/9LELpubonoa+eBx+0Yy0USVQrgiBkZX4UF4Q8ttjC/kD1sBCCC2iPPWw9jQvo2mvNRN57bwuxC+ax07uEczVxoq2fcUbj3HUf+Yg9yV9xhblKxo61cpH4aTmEkg4ebKGnQRA6Omz6yEKCAH3LbRQ60MOxJqlVwsExY2DTJlizpjb7a3ZcEPIQqc28ymn7BDo7Y6vk9ttLm7hLlpir4ItfhO99z9xHIczQ6V2CO+InP7H1119vnLsu3LxXrIitgyBY//mftv6d78SCtfPOsSC8/LKJQr4gTJwI227btyKN7rrLloXGWdTqvISw1az0I7ggFKAW8yqnDQt9++34uy64wASiGNddZ6l7P/tZM5O32irbbqNG3IzDfATbblv/7w5su61ZidBVEFTj6yfpP99557hT+fnnbZkvCCKWK6kvWAhB/J5+2tZ7M7giCEJW+hFcEArQEwuhsxP+8If09VetsuWECeYXvvXWwhf25s0WRjdrlg2YGTIEPv5xuO22vtURWEsaMRajvd1+/0bPWhaEICwDhdq1005mIagWFwQwy2PxYjjvvNq2tdbkcvD5z8eWQW+OsB4zxpYuCBmmWkHI5ewJPkyOnubJJQjCpZfaU9+cOYVvdPfcY9bEF78Ylx13nA06OvXUytva10lrGdX6JvHCC6Vn2+ptwtPxNdfY+v77d7/G8v3nO+9sgQhr1pggbLUV7LBD933vt5/dWH/4w95qfW14/XW46SYThd5mxx1tmRVBaHjCukpe9Uhup6q6++6qJ5xQ+Xavvaa6zTZxMqw0/O53Vvexx1Rvvrn4tkcfbeUbNsRl77yjOmRI+u/qDeqd8KuSxGOdnbX9bTZuVB04UPU736ndPntC2mO79db4Gps1S/WDHyxc7803K7t2G8UPf2htfOaZ+lx/222n+k//1Pvf05vgye2qZ8iQ6sJOjzjCEp+Fp4o0BAvhv/4LTjwxLg/WxSGHdJ3uM6Q+zuVsgNKsWVbeqLC4erttcrm4MxHsPBVyF6xfbyN3a8myZeae23XX2u63twmD05YtKxxyCvb7bbNNvN6sgx43b7ZJaw45xKLz6tG+LI1FcEEoQDUuo3vvtRw355xjN6IwmrgcQRB+8AO7sbW12frJJ9v6/PkWAbLbblaeHHgjYn0IAAMG1P8P3KhkaOE3gjgWP8nBB5tbJCRtq9XNrb3dliH0tNGkDa0MgrB0qWVGLSYIqjZ+AZo38+kdd9jUpV/5Sv2+c8wYF4RMU2mU0XvvWVItgPPPt/lv160za6Ecq1aZeISkevvua8tf/9r8pB/7mN2ILr2063bhDxyelv/85/r9gYMfe/vtbb3eT5OPPgrjx9tvdvPNXT9TtdGrYJlBwc5lLX6bEGHULBZC2uPZbjt7yPnzn+0Ju5AgBEInarNy+eW2nD27ft/pFkLGqcRCyOWsfkgYNnSohY9CulGfq1bFN9bABRdYeoIvfxn+9Ce7+I88svATYfhzh+iRaqj0RpnLmdiFJGLr19f3abKtzQZnnXyyWUhJ9973v2/L88+3WHzonsytWtrbLW1ISIvcVxCxSKMwg1opQRg71s5rs43MDQ8h8+fb+qBB9XsIGT3aEgZ2dPT+dzWaVIIgIrNEZImItIvIuQU+HywiN0WfLxSRcYnPzovKl4jIUYnyESJyi4j8VUSeE5H98/fbKCoVhH//93hd1TJNQrqUFIUE4aKLbFKOkKLipz+NvyufXXYxd1G1N70336yuH2DhwvgPUs/BTK++aoOEWlutz2XdOst4GW4YIWHbxRfDpz9t72uVjuGFFyw8eEAffIzaeec4S245QejosOuimcjlus5vXE+X1pgxFk6ehak0y17aIjIQuBw4GpgKnCwiU/OqnQq8qaoTgZ8Bl0TbTgVOAvYAZgFXRPsD+AVwl6ruDuwNNE0WlUr7EF580Z5YArvuauuLF5fftpAg5HKw++5xG3bdtfjT0MCBlsOmGgth1arqn3YfeCC+MYZ8+vXgscds2doKhx1mHaE332wWyw47xGlAVOHdd62NleSKKkV7e/P0H1RK6EcYPjyeXawQIQ3GihXp910vy/CJJ+rzPfkUG5zWbP0rtSDNs850oF1Vl6rqRuBGIN+DNxu4Lnp/C3CYiEhUfqOqvqeqLwLtwHQRGQ4cBFwNoKobVXVtzw+nNgwZYlMTpmXpUntSDy6dlha7oacRhNdeKywIlWRtrEYQcjm7gQZ3S6X9AA88APvsY2mT6ykIbW12k99nHxPdT37Ssr7+5CdmLdx4Y1x3yy3tib4WgtDZaee5rwvC0KGlB9VVIwj1ijR74gmb9yFYgfWimCD0x0mq0gjCGCCRTZ0VUVnBOqraAawDRpbYdjywGvjfIrJIRH4pIsMKfbmInCEibSLStrpOYS1DhlQ2Cc2LL1onZ/JmOnVq+RtRR4cNFsoXhEqZNMmeXkulvcgnl7NQ10AlJvjGjZaP/6CDbJDWggX186+2tdkAvjBK9cQT43P1059aR3Kyr2XKlNoIwquvmsXWLB3KlRLSYL/6aul6lQrC9ddX36ZKeeIJS+pY7xtxfj6jzZu7B3n0FxrlDW0BpgFXquoHgfVAt74JAFW9SlVbVbV11KhRdWlciPhJSxCEJHvsYSF+pSKN1qyxm3ChUaOBNKGFkyfbzaqSpzqwRGeBSsSkrc2+78AD7bV+PSxaVNl3V4OqRRi1ttp6LhePwwA488zuT79Tp1r/Sk8Fq9lCTislWAjl2HFHs8DKXUuhz+aUU2y9tyPNOjtt/od99umd/Zdi++3NNfvKK3Z8LS1w9tn2WbOO16iWNIKwEtgpsT42KitYR0RagOHAmhLbrgBWqGrojrztxFA/AAAW5klEQVQFE4iGEi7yoP5pTvZbb9mNfcKEruXBlx06mAsRxiCUshDSXGihk7DSjuVkjvwQUpmGENYZBAHq4zZascJ+sw99yNaDa21t5GwsZOVMnWrpi0sdX5rfuNlCTishl4vTYkPp63qLLUwU0giCqrkMwa693uzkfeEFe/BohCAMHGi/SRCEj30s/qxZx2tUSxpBeBSYJCLjRWQQ1kk8L6/OPCB6VuB44N5ouPQ84KQoCmk8MAl4RFX/DiwXkWi4FYcBNer6q55wkYeooeXLy5/sMGFKvoUwNep2L9WPkEYQ0jB5si0r7UdYtiyefa2SJ/y//MVcMaNGmTk9YUJ9BCEMSAsWQqDUIMCQFbSU2yiNC6K93Z4M0z5pNxPhug7Xarmb2Nix6a3NkEW1tyfWefJJWzZCECAei7BihWUN2HprK3/77ca0p7coKwhRn8BZwHwsEuhmVV0sIheJyCeialcDI0WkHfgGkftHVRcDN2M3+7uAr6hqyM35VeBXIvIUsA/wr7U7rJ4RJk9PulSKUUwQ0kQa1UoQRo+2zsJqLIRDDrEbXVpB2LzZZqo66KC4bMYMK+vt2PW2NnuyDU+lSYq51nbf3ZbFblhp/9AvvADjxsVjL/oi48alq5dWENavj8NTaxXJVYwnnrDffmp+fGOdCHMrX3utua/CvBhhbEd/IVUfgqreoaqTVXVXVb04KrtQVedF7zeo6gmqOlFVp6vq0sS2F0fb7aaqdybKn4j6Bj6gqseqatNEPlcjCPkuo5YWSzdR6o9SK0EQMbdRJRaCqh3fpEnm3korCE89ZW6ypCAceKBloDzrrMraXSltbdbuYNUkKfa0+7732VN9/nkI7sHwpFfOPdiXQ06TpOmTGjs23YQwSdGohyBMmRJPJlVvxoyx4736agt3/tzn7CEsDJTrL/TBITa9T3ALpBGEpUvtppJMDBbYY4/yFsLAgYW3rZRJkyqzENautQ7vnXeGD37QBCHNE36y/yAQ3l9xRfrvr5RknqdKKRTxFdwoYfaxsJ4UhPBe1c5jX+w/yCeNr3vsWBP9cpF2wV201Vb1EYRGzmM9erT9Z156CU47zQJPDjnEBSETDBtmg3deeql83RBhVCi2O0QahRQK+axaZX74Wox8nTzZ2rJpU7r6oUN5l11MEFatKh+SCLEg7JQIFZg8uedWTilyOfuN3njD1iuN7JgyxTr38yOpOjpi3/S//Zu5QJKEvoU1a2y8Rn+wENIQQk/LWQlBEA49tPDvWytWr7a2NKr/AOLQU4Bjj7XlUUeZ5bh0aeFt+iIuCEXYZZf0LqP8/oNA8Hf+4AeFPy80SrlaJk2yG1waEYNYEIKFAKXdRsHFcuuttp5Mzz1gQOz+6o0wvDlz7Ek+iFClkR1Tp1oakPzzuWSJle+7r930w6QzYH0iYFk1L77Y3vcHCyENIcFduX6EIAhHHGFiunx56frV0ugOZeia9C+4rY6KEvHcfXftvqfR0UouCEVIIwghciO//yAQQk+LUUtBqDTSKCkIwRR//PGudfLdJ8lcLuGmfP/9tgyfbbtt7SNO7rjD5voNSQMrJQhzvlsjHO9111na55/8xPpGRLq6wX7+c3v/iU/0r5jzYqQdnLZ8uV2/4YGit9xGIWVFo1xGuVx884f4oef//B/7/8yfX7trotGjn10QihAEoZRf/bXX7AmzkIUQ8hEFCj05F0pbUS2VjkV4+WWLgtp+e+sDmTixu4WQf3GWsiDCcbS02GCx5LY9+bOoms92wgT4whfSzwGQJISehht74PHHrYN6t91sHouXX7bw2aFDYxFRNeshvO9PMefFCO6RNIKw007pQnuTVPr7PfGEBQeUysHUmxRLJTN3rgnFvffW5kZeSXaE3sIFoQjjxtnN/vXXi9cpFnIK8UV0xBG2XuhmUksLYbvtYMSIyiyEnXaK+y9Cx3Lg0Ue7bxOe1M45p/A+58yB//7v+De78kpzJfTkz/K731leqVzOBk1VczPeZhsbWJQ/mc6iRfbU2dICH/94LALjxtmfPLDttlU2vo8yZIj1baUVhJEj7TpOaxlWej088UTzxvsfdVTPb+TBHRvG0zRy9LMLQhHShJ4WCzlNsn+U1Dv/gl6/3l6l0lZUQgg9TU4vWYply+JjBBOEl16KJ22fPj3eb7g4Fy2ybS65pPh+P/ShuHP2zDPjnEPVsGlTnMgspLKulnz3XWenHc+0aXZsAwfGT7jPPmsCcvDBcf1qLJO+TJqxCEEQIF3uLohn2VuyxJalbnrf/a71v/X2oLdKSF4HuRwcf3y8Xu2NPJezcO7AM8800BJNM/Fys7z23XffVBNK14JFi+yZ/pZbitf53veszrvvFq9z111W5557upa/+KKVX311TZqrqqqf+Uz6CdLHjFH9whfi9TvvjCdYF1HdYYfu+5o8WfXYY9PtP7aJur7SToo+Y0bPtg/MmVN4P1/9qi1/+cvu7XZUjzlG9QMfKP75unX2W11yia2feabq8OGqnZ2F6xc7D8V+77vv7vk1VC/Gju35dfO5z6kOHmz7ufTS2rQrCdCmKe6xbiEUIa2FsOOOhQdKBT78YXtqeOihruW1GpSWJPQjhIl1irFxow3DT6ZhmDbNnpLBZmn75jftfUgD/s475o6qJNJDNY7Wue229E89q1bZdgMGwFVXxfuq5qkpuO5CSO13v2vrM2bY+rSGZ9BqTspZCCGiKFgIU6ZY+vFiocu5nPXFDB1q62efbS5A6BrdNWeOWQUh99Idd6RPA98oQh9KtSxbZlPmfvnL5vZNuivrjQtCEUaMsI6scoJQLOQ0uZ899uhdQQg+yPBHCTnvi/1xVq60P1YQhDA3wuYoqcjMmXE/wX332fKpp2ybEFFSjmBah7xDaXMdvfGGTY8JJiKnn55uu3LsuKMtf/UrO47HH7cbUr4rKWuuoWKMHWvn4t1347Lk9ZQvCKH/pZR758or4/394hfxmJlTT7Xr9fzzbbbA5Lidj3609PwNzcCUKXYtlQpAKcWJJ9ryG9+A446zyL3wX6w3LghFECkferp0aen+g8D++1vYZHLgTq0FQTUeuDV3buknqeSgtOT2ySexjg7r5ApPK6HDOa0ghO8ePNiEJ1gK5bYZOTLOLBrCPJO+/J4we7aJ+IIFJgh77dV1prtku7NOocFpyc7gYoJQrB9hwwYb/Ddrlolu8nr71rds+R//Yctvfzu+IYZ6zSzUU6aYuFUzDmPNGpuC9tOftt9y5kwbEd2o2eFcEEpQShA2bbLPylkIYE+8a9d2TYUdBKGWUzyEFBjlEm4lxyAUY+BAG3QWLIRFi+xmHW4UlfCZz9jUl/kjgfPJ5Sz+f889bT3cDGqVQOz66y2C5le/ijuUncLkj0UIAxIDy5ebWIcQ1R12sOvvuusoyAknWJj1v/xLd9EdFk2NFcJ7L7kkdl8Gmlmog8uoms7vK6+05b/8iy0PPdSWjXIbuSCUYJddio/8DU8DaQUBurqNVq2yP8KwgvPEVc9++9n3lJoTOohcMv1EIPkkduih9rT+8sv2xLLPPtWZ7zNmmMWRnCS9EK+8YpbECSdU/h1p2HprsxKuvdZCY10QihMEIUw6dNxxth4iaebNs/m4Qz+AiN0Yw5zXSTo74Q9/sN873PACc+YUj/NvZqsgSTWCENy8YbDlXnvZ+n/8h+3PBaEJGTfOnuwLxRkHt0YaQZg0yZ6u8wWhN/L/fOc7lndn4cLidZYtM8ukXNbQmTNteffd8PTT6d1F+XzkI3axl+tH+O1v7UZwwgm9dzP4zGdiP3a1x5MFQqqGYNUG9+LTT9s52m677g8UoT/mmWdsGa6lf/s3W37rW90fKEo9+TezVZBk1Cj7f1cqCJ2d8diDZIf5zJn2X0mbl6yWuCCUoFCkUVD2EAUxc2b52GMR60dYsCCu99prFu1Taw480KJzSrlZli1LN9HLHnvYxX7FFdbWam+gI0bYE1C5foTf/MbcRVOm9N7N4Kij4oFmheZVcIxhw2IX5IknxmL++9/bMjkGIfwn/vM/bT087c6da8uvfc3KP/3p8v+VvmIVJAnWUaWpO1591SKz8jn0UHOvfulLtWlfRaSJTW2WVz3HIaiqPvyw6fbtt3f/bK+9Kos9/td/7Rp3/YEP9F7M+777qh58cPHPp0xR/dSn0u3rhBPidi9eXH2bvvIV1a22Ut20qfDnK1fa+Ie5c6v/jnIUi4Vvtrj2RlPsd3rf+1SnT7exBltuqfq1r3XfFlT32EN1iy3i7c4+u/+P7zj9dNWRIyvbJoy1+Pznu5a//nrpMRrVgI9D6DnFxiK8/LKZzpUQ+hHAYrDDpO29wSGHWFRTsh8hmdt/2bJ0E6BA7DYCy/lTLTNm2FiGkLkyn1NPjd1FvUUxX3VfcU3Ui2K/07nnWj/Q4sU21qVQHxTY50l3xy9+0etNbjhTplineBiJnYYwV8qPftS1fOTIxmV2dUEowfbbW9hkviDcfrst084QlsvZTTpw6aWxH7s38pYccoj1Izz8cFyWzO2/fn3pPoYkSUHIj/yohDAQ7PzzC39+112xu8hpTmbPtmWIjCkWlBDClqHvdRBXSzUdy4sXW19Msi8xuN9C2Gnd8xqlMSOa5VVvl5Gq6qRJqiee2LXsyCMtjUOl/P3v9vcIw/t7y4xeu1Z1wADVgw6y9SeesO+aMkV10KD05mitXSzjxnX93rCf556z8t50F+XjbqJ0JH+nzk7VCRPM9QeqCxaU3ra/u4mSvPSSHe+VV6bf5iMfKe7abW+3/Z1zTk2al9pl1PCbfCWvRgjC4Ydb3p/AW2/ZTfWb36xuf8k/SW/+YVpbC9/Mq7nBb9hQm7Z+7nO2n1tvVX311erb4zSOr389Pk8rVpSum6XzuHmz6rBhqv/8z13Li/0GnZ2W++nLXy6+T1Ddemt7wOspaQXBXUZl2GWXrv72u++2iJtjjqluf0nTuTfN6KSLKgyNT952k+vlzNHBg3vWlmAG33CDrX/qUxbDDuaGCukp0rbHaRzBbQRxOpBiZOk8Dhhg85/ku4yKpfp+5RWLMCo1idYZZ1jI+7//e+3aWZY0qtEsr0ZYCCE66MYbbX3vvVW32aZ4tEyjSZtVstIn/lo97ZWyVJzmZ9Mm1W239fNViM9+1jKfBm67rfjvFCKM7ruv9D4PP1x1xx1Vzz+/Z23DLYSeEZ5qQ6Ktk06y9SefhKOPtklVmpG0oz4rtU5q+bSXpn1O8xEmKQo5sxo5kUszMmWKpfqYMcN+l2OPtfJCv1OIMCo3ze63v20Zh8O83r1OGtUAZgFLgHbg3AKfDwZuij5fCIxLfHZeVL4EOCpvu4HAIuAPadrRCAtB1W5Zp58eP8kGa6HZacanuKSl0Yztc9Lh5647t97a1eJtaSn+O512mup225XfZ2en6rRptp+OjurbRq0sBBEZCFwOHA1MBU4Wkal51U4F3lTVicDPgEuibacCJwF7RKJyRbS/wNlAE82HVJwwChNia6HZn4ya8ak7+Zs1Y/scp1qmJu6KxxwTz/YXkvYlWby4vHWQy1nfxOOP23pLSx3uO+UUA9gfmJ9YPw84L6/OfGD/6H0L8Dog+XXz6o0F/gTMpMktBH+qdZyuZCmCKA2l+u7uvLNr3RBhdOaZ6fbd2dnz+w417EMYAyQzfa+IygrWUdUOYB0wssy2PwfOARKzBHRHRM4QkTYRaVtdyTDAGtLsloDj1Bv/T3Ql9N299pqtq1piTBF49NGudUOE0dR8P0sR6jlBUEM6lUXk48AqVS2QLLcrqnqVqraqauuoWk4eUCXu5nAcpxjJUcfDh1soan7a97Qdyknqdd9JIwgrgeQg9bFRWcE6ItICDAfWlNj2AOATIvIScCMwU0T+q4r21x1/MnIcpxTJm/f06SYIIaoOqhOEet130gjCo8AkERkvIoOwTuJ5eXXmAadE748H7o38VvOAk0RksIiMByYBj6jqeao6VlXHRfu7V1U/W4PjcRzHaSjJm/eHPmRznySn1wxpspvA4dGNstH0qtohImdhHcIDgWtUdbGIXIR1VMwDrgZuEJF24A3sJk9U72bgWaAD+IqqNmj6aMdxnPoyfbotH3nE5iDp7Cw/UVQjEU3aMk1Oa2urtrW1NboZjuM4qXjvPZu69eyzYejQwqkswjSivYmIPKaqreXqNel4W8dxnL7P4ME2t8Ejj8B999nc0mvX2hS8zfgs7qkrHMdxepEPfQgeewzuvNOW557b6BYVxy0Ex3GcXmT6dLj8cptTeuxY+PznLedRM+IWguM4Ti8SOpbXrYNzzoFBg5o3fN0FwXEcpxeZPNk6lgFOO62xbSmHC4LjOE4vkcvZJFBvvWXrQ4c2d2JMDzt1HMepAyKNiyxKG3bqFoLjOI4DuCA4juPUhb6QGNMFwXEcpw40a79BEhcEx3EcB3BBcBzHcSJcEBzHcRzABcFxHMeJcEFwHMdxgD42ME1EVgMvV7n5dsDrNWxOXyCLxwzZPO4sHjNk87irOeZdVLXsHG19ShB6goi0pRmp15/I4jFDNo87i8cM2Tzu3jxmdxk5juM4gAuC4ziOE5ElQbiq0Q1oAFk8ZsjmcWfxmCGbx91rx5yZPgTHcRynNFmyEBzHcZwS9HtBEJFZIrJERNpFpImnt+4ZIrKTiNwnIs+KyGIROTsq31ZE/igiz0fLbRrd1lojIgNFZJGI/CFaHy8iC6NzfpOIDGp0G2uNiIwQkVtE5K8i8pyI7N/fz7WIfD26tp8RkV+LyJD+eK5F5BoRWSUizyTKCp5bMS6Njv8pEZnWk+/u14IgIgOBy4GjganAySIytbGt6jU6gG+q6lRgP+Ar0bGeC/xJVScBf4rW+xtnA88l1i8BfqaqE4E3gVMb0qre5RfAXaq6O7A3dvz99lyLyBjgn4FWVd0TGAicRP8819cCs/LKip3bo4FJ0esM4MqefHG/FgRgOtCuqktVdSNwIzC7wW3qFVT1VVV9PHr/NnaDGIMd73VRteuAYxvTwt5BRMYCHwN+Ga0LMBO4JarSH495OHAQcDWAqm5U1bX083MNtABbikgLMBR4lX54rlX1AeCNvOJi53Y2cL0aDwMjROT91X53fxeEMcDyxPqKqKxfIyLjgA8CC4EdVPXV6KO/Azs0qFm9xc+Bc4DOaH0ksFZVO6L1/njOxwOrgf8ducp+KSLD6MfnWlVXAj8GlmFCsA54jP5/rgPFzm1N73H9XRAyh4hsBfwW+JqqvpX8TC2krN+ElYnIx4FVqvpYo9tSZ1qAacCVqvpBYD157qF+eK63wZ6GxwOjgWF0d6tkgt48t/1dEFYCOyXWx0Zl/RIR2QITg1+p6q1R8WvBhIyWqxrVvl7gAOATIvIS5g6cifnWR0RuBeif53wFsEJVF0brt2AC0Z/P9eHAi6q6WlU3Abdi57+/n+tAsXNb03tcfxeER4FJUSTCIKwTal6D29QrRL7zq4HnVPWniY/mAadE708Bfl/vtvUWqnqeqo5V1XHYub1XVT8D3AccH1XrV8cMoKp/B5aLyG5R0WHAs/Tjc425ivYTkaHRtR6OuV+f6wTFzu084PNRtNF+wLqEa6lyVLVfv4CPAn8DXgDOb3R7evE4Z2Bm5FPAE9Hro5hP/U/A88A9wLaNbmsvHf8hwB+i9xOAR4B24DfA4Ea3rxeOdx+gLTrftwHb9PdzDcwF/go8A9wADO6P5xr4NdZPsgmzBk8tdm4BwSIpXwCexqKwqv5uH6nsOI7jAP3fZeQ4juOkxAXBcRzHAVwQHMdxnAgXBMdxHAdwQXAcx3EiXBAcx3EcwAXBcRzHiXBBcBzHcQD4f7zlvobYaLgaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=temperature)\n",
    "agent_dqn_cnn = DQN_CNN(grid_size=size, lr=.01, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "history_losses_dqn_cnn, history_scores_dqn_cnn = train(agent_dqn_cnn,env,epochs_train,prefix='cnn_train')\n",
    "\n",
    "plt.plot(history_losses_dqn_fc,marker=\"+\",color=\"b\",label=\"dqn_fc\")\n",
    "plt.plot(history_losses_dqn_cnn,marker=\"+\",color=\"r\",label=\"dqn_cnn\")\n",
    "plt.xlabel(\"episodes\") ; plt.ylabel(\"mean training loss during episod\") ; plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_scores_dqn_fc,marker=\"+\",color=\"b\",label=\"dqn_fc\")\n",
    "plt.plot(history_scores_dqn_cnn,marker=\"+\",color=\"r\",label=\"dqn_cnn\")\n",
    "plt.xlabel(\"episodes\") ; plt.ylabel(\"score during episod (0.5*win-lose)\") ; plt.legend()\n",
    "plt.show()\n",
    "\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dqn_cnn = DQN_CNN(grid_size=size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 16)\n",
    "agent_dqn_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_dqn_fc = DQN_FC(grid_size=size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 16)\n",
    "agent_dqn_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "\n",
    "for temp in [0.1, 0.3, 0.5]:\n",
    "    print(\"TEMPERATURE : \", str(temp))\n",
    "    env = Environment(grid_size=size, max_time=T,temperature=temp)\n",
    "\n",
    "    print('Test of the CNN')\n",
    "    test(agent_dqn_cnn,env,epochs_test,prefix='cnn_test')\n",
    "    print('Test of the FC')\n",
    "    test(agent_dqn_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO :comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    \n",
    "    decrease_rate_epsilon = (agent.epsilon-0.1)/epoch \n",
    "    #we decide that at the end of the training, epsilon is equal to 0.1\n",
    "    \n",
    "    history_losses = []\n",
    "    history_scores = []    \n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for e in range(epoch):\n",
    "            \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "        \n",
    "        loss = 0\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        t = 0\n",
    "\n",
    "        while not game_over:\n",
    "            \n",
    "            # The agent performs an action\n",
    "            action = agent.act(state, train = True)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss += agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "            \n",
    "            t+=1\n",
    "            \n",
    "        loss /= t\n",
    "            \n",
    "        history_losses.append(loss)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score_episode = 0.5*win-lose\n",
    "        score += score_episode\n",
    "        history_scores.append(score_episode)\n",
    "        \n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, score_episode))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "        ############\n",
    "        #Update epsilon\n",
    "                \n",
    "        agent.set_epsilon(agent.epsilon-decrease_rate_epsilon)\n",
    "\n",
    "                \n",
    "class EnvironmentExploring(Environment):\n",
    "    \n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        \n",
    "        super(EnvironmentExploring, self).__init__(grid_size=grid_size, max_time=max_time, temperature=temperature)\n",
    "        self.is_visited = np.zeros((self.grid_size,self.grid_size)) #has the cell been visited by the past\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1 #self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x -1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x +1\n",
    "            else:\n",
    "                self.x = self.x - 1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        \n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        \n",
    "        #the new state is visited\n",
    "        self.is_visited[self.x,self.y] = 1\n",
    "                \n",
    "        #we have one more layer caracterizing a state now\n",
    "        state = np.concatenate((self.is_visited.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "        #state visible for the rat\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "        \n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "        \n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.board[self.position < 0] = 0\n",
    "        \n",
    "        self.t = 0\n",
    "        \n",
    "        #the initial state is visited\n",
    "        self.is_visited[self.x,self.y] = 1\n",
    "        \n",
    "        #we have one more layer caracterizing a state now\n",
    "        state = np.concatenate((self.is_visited.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=temperature)\n",
    "#agent = DQN_CNN(grid_size = size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "\n",
    "#init epsilon is 0.9, it will decrease linearly through epochs to reach 0.1 at the end of training\n",
    "agent_dqn_cnn_explore = DQN_CNN(grid_size=size, lr=.1, epsilon = 0.9, memory_size=2000, batch_size = 16,n_state=3)\n",
    "train_explore(agent_cnn_explore, env, epochs_train, prefix='cnn_train_explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "test(agent_dqn_cnn_explore,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))\n",
    "\n",
    "# Comparison\n",
    "\n",
    "agent_dqn_cnn_explore = DQN_CNN(grid_size=size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 16)\n",
    "agent_dqn_cnn_explore.load(name_weights='cnn_train_exploremodel.h5',name_model='cnn_train_exploremodel.json')\n",
    "\n",
    "for temp in [0.1, 0.3, 0.5]:\n",
    "    print(\"TEMPERATURE : \", str(temp))\n",
    "    env = Environment(grid_size=size, max_time=T,temperature=temp)\n",
    "\n",
    "    print('Test of the CNN (train with epsilon constant 0.9)')\n",
    "    test(agent_dqn_cnn,env,epochs_test)\n",
    "    print('Test of the CNN (train with decreasing epsilon from 0.9 to 0.1)')\n",
    "    test(agent_dqn_cnn_explore,env,epochs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO : http://ciml.info/dl/v0_99/ciml-v0_99-ch18.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "class Mimicker():\n",
    "    \n",
    "    def __init__(self, n_state=2, n_action=4):\n",
    "        \n",
    "        # number of action\n",
    "        self.n_action = n_action\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "        \n",
    "        # Batch size when learning\n",
    "                \n",
    "        model = Sequential()\n",
    "    \n",
    "        model.add(Conv2D(8, (3, 3), activation='relu', padding='same',input_shape=(5,5,self.n_state,)))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.n_action),activation='softmax')\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        opt = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        #opt = sgd(lr=lr, decay=1e-4, momentum=0.0)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def act(state):\n",
    "        return np.argmax(model.predict(state)) #action with highest probability\n",
    "        \n",
    "    def learn(trajectories,epochs=100,batch_size=16,prefix='', viz=True):\n",
    "        \n",
    "        states = []\n",
    "        actions = []\n",
    "        for (state, action) in trajectories:\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            \n",
    "        label_actions = to_categorical(actions,num_classes=self.n_action)\n",
    "        \n",
    "        early_stopping_monitor = EarlyStopping(patience = 5)\n",
    "        \n",
    "        history = self.model.fit(states,actions,\n",
    "                                 batch_size=batch_size,epochs=epochs,\n",
    "                                 validation_split = 0.2,callbacks=[early_stopping_monitor],\n",
    "                                 verbose=1)\n",
    "        \n",
    "        if viz:\n",
    "            plt.plot(list(range(epochs)),history.history['loss'])\n",
    "            plt.xlabel(\"epochs\") ; plt.ylabel(\"train loss\")\n",
    "            plt.show()\n",
    "            plt.plot(list(range(epochs)),history.history['val_loss'])\n",
    "            plt.xlabel(\"epochs\") ; plt.ylabel(\"validation loss\")\n",
    "            plt.show()\n",
    "\n",
    "        self.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        \n",
    "        #model.compile(\"sgd\", \"mse\")\n",
    "        model.compile(\"adam\", \"mse\")\n",
    "        \n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_test = 10\n",
    "trajectories = test(agent_cnn_explore,env,epochs_test,prefix='cnn_test_explore')\n",
    "\n",
    "agent_mimicker = Mimicker(n_state=2, n_action=4)\n",
    "agent_mimicker.learn(trajectories,epochs=100,batch_size=16,prefix='mimicker_train', viz=True)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "test(agent_mimicker,env,epochs_test,prefix='mimicker_test')\n",
    "HTML(display_videos('mimicker_test10.mp4'))\n",
    "\n",
    "# Comparison performances\n",
    "\n",
    "epochs_test = 10\n",
    "\n",
    "for temp in [0.1, 0.3, 0.5]:\n",
    "    print(\"TEMPERATURE : \", str(temp))\n",
    "    env = Environment(grid_size=size, max_time=T,temperature=temp)\n",
    "\n",
    "    print('Test of the CNN (train with decreasing epsilon from 0.9 to 0.1)')\n",
    "    test(agent_dqn_cnn_explore,env,epochs_test)\n",
    "    \n",
    "    print('Test of the Mimicker Agent')\n",
    "    test(agent_mimicker,env,epochs_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
